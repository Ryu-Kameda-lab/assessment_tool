# phase3_answer_engine.py

import os
import json
import time
import chromadb
import google.generativeai as genai
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv
from question_spec import load_question_spec, make_search_query

load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# ===================================================
# è¨­å®š
# ===================================================
CHROMA_DB_PATH  = "./chroma_db"
COLLECTION_NAME = "manual_chunks"
EMBED_MODEL     = "paraphrase-multilingual-mpnet-base-v2"
TOP_K              = 4    # 1å•ã‚ãŸã‚Šä½•ãƒãƒ£ãƒ³ã‚¯å–å¾—ã™ã‚‹ã‹
BATCH_SIZE         = 10   # ä½•å•ã¾ã¨ã‚ã¦APIã«æŠ•ã’ã‚‹ã‹
GEMINI_MODEL       = "gemini-2.0-flash"
BATCH_INTERVAL_SEC = 10   # ãƒãƒƒãƒé–“ã®å¾…æ©Ÿç§’æ•°ï¼ˆAPI rate limitå¯¾ç­–ï¼‰
MAX_RETRIES        = 3    # ã‚¨ãƒ©ãƒ¼æ™‚ã®æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°
RETRY_BASE_SEC     = 30   # ãƒªãƒˆãƒ©ã‚¤å¾…æ©Ÿã®åŸºæº–ç§’æ•°ï¼ˆæŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•: 30â†’60â†’120ï¼‰


# ===================================================
# ChromaDBæ¤œç´¢
# ===================================================
def search_chunks(query: str, collection, model, top_k: int = TOP_K) -> list[dict]:
    """
    ã‚¯ã‚¨ãƒªã«è¿‘ã„ãƒãƒ£ãƒ³ã‚¯ã‚’æ¤œç´¢ã—ã¦è¿”ã™
    """
    vector  = model.encode([query]).tolist()
    results = collection.query(
        query_embeddings = vector,
        n_results        = top_k,
        include          = ["documents", "metadatas", "distances"]
    )

    chunks = []
    for doc, meta, dist in zip(
        results["documents"][0],
        results["metadatas"][0],
        results["distances"][0],
    ):
        chunks.append({
            "text":     doc,
            "page_num": meta["page_num"],
            "score":    round(1 - dist, 3),
        })
    return chunks


# ===================================================
# ãƒãƒƒãƒå›ç­”ç”Ÿæˆ
# ===================================================
def answer_batch(questions: list[dict], collection, embed_model) -> dict:
    """
    10å•åˆ†ã®è³ªå•ã‚’å—ã‘å–ã‚Šã€
    å„è³ªå•ã«å¯¾ã—ã¦æ¤œç´¢â†’Geminiå‘¼ã³å‡ºã—ã§å›ç­”ã‚’è¿”ã™

    è¿”ã‚Šå€¤: { QID: {"answer": "...", "evidence_pages": [12, 13]} }
    """

    # å„è³ªå•ã®æ¤œç´¢çµæœã‚’ã¾ã¨ã‚ã‚‹
    context_blocks = []
    for q in questions:
        query  = make_search_query(q)
        chunks = search_chunks(query, collection, embed_model)

        # æ¤œç´¢çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆã«æ•´å½¢
        refs = "\n".join([
            f"  [ãƒšãƒ¼ã‚¸{c['page_num']}] {c['text']}"
            for c in chunks
        ])
        context_blocks.append(
            f"ã€Q{q['qid']}ã®å‚è€ƒæƒ…å ±ã€‘\n{refs}"
        )

    # è³ªå•ãƒªã‚¹ãƒˆã‚’æ•´å½¢
    q_list = "\n".join([
        f"Q{q['qid']}: {q['text']}\n  â€»å›ç­”æŒ‡ç¤º: {q['output_rule']}"
        for q in questions
    ])

    # Geminiã¸ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    prompt = f"""
ã‚ãªãŸã¯åœ°åŸŸé˜²ç½è¨ˆç”»ã®ã‚¢ã‚»ã‚¹ãƒ¡ãƒ³ãƒˆæ‹…å½“è€…ã§ã™ã€‚
ä»¥ä¸‹ã®ã€å‚è€ƒæƒ…å ±ã€‘ã¯é˜²ç½ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‹ã‚‰æŠ½å‡ºã—ãŸæ–‡ç« ã§ã™ã€‚
ã“ã®æƒ…å ±ã‚’æ ¹æ‹ ã«ã—ã¦ã€å„è³ªå•ã«æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

ãƒ«ãƒ¼ãƒ«ï¼š
- å‚è€ƒæƒ…å ±ã«è¨˜è¼‰ãŒã‚ã‚‹å ´åˆã¯ã€ãã®å†…å®¹ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã¦å›ç­”ã™ã‚‹
- å‚è€ƒæƒ…å ±ã«è¨˜è¼‰ãŒãªã„å ´åˆã¯ã€Œè¨˜è¼‰ãªã—ã€ã¨å›ç­”ã™ã‚‹
- å›ç­”ã¯JSONå½¢å¼ã®ã¿ã§è¿”ã™ï¼ˆä»–ã®æ–‡ç« ã¯ä¸€åˆ‡ä¸è¦ï¼‰
- æ ¹æ‹ ãƒšãƒ¼ã‚¸ç•ªå·ã‚‚å¿…ãšå«ã‚ã‚‹

{'='*50}
ã€å‚è€ƒæƒ…å ±ã€‘
{'='*50}
{chr(10).join(context_blocks)}

{'='*50}
ã€è³ªå•ãƒªã‚¹ãƒˆã€‘
{'='*50}
{q_list}

{'='*50}
ã€å‡ºåŠ›å½¢å¼ï¼ˆã“ã®JSONã®ã¿è¿”ã™ã“ã¨ï¼‰ã€‘
{'='*50}
{{
  "Q1": {{"answer": "å›ç­”å†…å®¹", "evidence_pages": [12, 15]}},
  "Q2": {{"answer": "å›ç­”å†…å®¹", "evidence_pages": [20]}},
  ...
}}
"""

    # Gemini APIå‘¼ã³å‡ºã—ï¼ˆãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰
    model_gemini = genai.GenerativeModel(GEMINI_MODEL)
    response = None
    for attempt in range(MAX_RETRIES):
        try:
            response = model_gemini.generate_content(prompt)
            break  # æˆåŠŸã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
        except Exception as e:
            is_rate_limit = (
                "429" in str(e)
                or "ResourceExhausted" in str(type(e).__name__)
                or "quota" in str(e).lower()
            )
            if is_rate_limit and attempt < MAX_RETRIES - 1:
                wait_sec = RETRY_BASE_SEC * (2 ** attempt)  # 30â†’60â†’120ç§’
                print(f"  âš ï¸  ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã€‚{wait_sec}ç§’å¾…æ©Ÿå¾Œã«ãƒªãƒˆãƒ©ã‚¤... "
                      f"({attempt+1}/{MAX_RETRIES})")
                time.sleep(wait_sec)
            else:
                print(f"  âŒ Gemini APIå‘¼ã³å‡ºã—å¤±æ•— (attempt {attempt+1}): {e}")
                # ãƒªãƒˆãƒ©ã‚¤ä¸Šé™ or äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ â†’ å…¨å•ã‚¨ãƒ©ãƒ¼åŸ‹ã‚
                return {
                    f"Q{q['qid']}": {"answer": "å–å¾—ã‚¨ãƒ©ãƒ¼", "evidence_pages": []}
                    for q in questions
                }

    # JSONãƒ‘ãƒ¼ã‚¹
    raw = response.text.strip()
    # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãŒå«ã¾ã‚Œã‚‹å ´åˆã‚’é™¤å»
    raw = raw.replace("```json", "").replace("```", "").strip()

    try:
        result = json.loads(raw)
    except json.JSONDecodeError:
        # ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã¯å…¨å•ã€Œå–å¾—ã‚¨ãƒ©ãƒ¼ã€ã§åŸ‹ã‚ã‚‹
        result = {
            f"Q{q['qid']}": {"answer": "å–å¾—ã‚¨ãƒ©ãƒ¼", "evidence_pages": []}
            for q in questions
        }

    return result


# ===================================================
# 105å•ã™ã¹ã¦ã«å›ç­”ã™ã‚‹
# ===================================================
def answer_all(collection=None, progress_callback=None) -> dict:
    """
    å…¨105å•ã«å›ç­”ã—ã¦çµæœã‚’è¿”ã™

    collection:        ChromaDBã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆçœç•¥æ™‚ã¯ãƒ‡ã‚£ã‚¹ã‚¯ã‹ã‚‰èª­ã¿è¾¼ã‚€ï¼‰
    progress_callback: Streamlitã®ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°ç”¨
    è¿”ã‚Šå€¤: { QID(int): {"answer": "...", "evidence_pages": [...]} }
    """
    embed_model = SentenceTransformer(EMBED_MODEL)

    if collection is None:
        print("ğŸ“‚ ChromaDBèª­ã¿è¾¼ã¿ä¸­...")
        client     = chromadb.PersistentClient(path=CHROMA_DB_PATH)
        collection = client.get_collection(COLLECTION_NAME)

    questions = load_question_spec()
    all_answers = {}
    total_batches = (len(questions) + BATCH_SIZE - 1) // BATCH_SIZE

    for batch_idx in range(total_batches):
        start = batch_idx * BATCH_SIZE
        end   = min(start + BATCH_SIZE, len(questions))
        batch = questions[start:end]

        qids = [q['qid'] for q in batch]
        print(f"  ãƒãƒƒãƒ {batch_idx+1}/{total_batches}: Q{qids[0]}ã€œQ{qids[-1]} å‡¦ç†ä¸­...")

        result = answer_batch(batch, collection, embed_model)

        # QIDã‚’æ•´æ•°ã‚­ãƒ¼ã§çµ±ä¸€ã—ã¦æ ¼ç´
        for q in batch:
            key = f"Q{q['qid']}"
            if key in result:
                all_answers[q['qid']] = result[key]
            else:
                all_answers[q['qid']] = {"answer": "å–å¾—ã‚¨ãƒ©ãƒ¼", "evidence_pages": []}

        # Streamlitãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®æ›´æ–°
        if progress_callback:
            progress_callback((batch_idx + 1) / total_batches)

        # æœ€å¾Œã®ãƒãƒƒãƒä»¥å¤–ã¯å¾…æ©Ÿï¼ˆAPIå‘¼ã³å‡ºã—é–“éš”èª¿æ•´ï¼‰
        if batch_idx < total_batches - 1:
            print(f"  â³ æ¬¡ã®ãƒãƒƒãƒã¾ã§ {BATCH_INTERVAL_SEC}ç§’å¾…æ©Ÿ...")
            time.sleep(BATCH_INTERVAL_SEC)

    print(f"âœ… å…¨{len(all_answers)}å•ã®å›ç­”ç”Ÿæˆå®Œäº†")
    return all_answers


# ===================================================
# å‹•ä½œç¢ºèªï¼ˆå˜ä½“ãƒ†ã‚¹ãƒˆç”¨ï¼‰
# ===================================================
if __name__ == "__main__":
    print("=== å›ç­”ã‚¨ãƒ³ã‚¸ãƒ³ å‹•ä½œãƒ†ã‚¹ãƒˆ ===")
    print("æœ€åˆã®10å•ã ã‘å›ç­”ç”Ÿæˆã—ã¾ã™...\n")

    client      = chromadb.PersistentClient(path=CHROMA_DB_PATH)
    collection  = client.get_collection(COLLECTION_NAME)
    embed_model = SentenceTransformer(EMBED_MODEL)

    questions = load_question_spec()[:10]   # æœ€åˆã®10å•ã ã‘ãƒ†ã‚¹ãƒˆ
    result    = answer_batch(questions, collection, embed_model)

    for qid, val in result.items():
        print(f"{qid}: {val['answer'][:60]}...")
        print(f"   æ ¹æ‹ ãƒšãƒ¼ã‚¸: {val['evidence_pages']}")