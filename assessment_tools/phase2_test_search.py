# phase2_test_search.py

import chromadb
from sentence_transformers import SentenceTransformer

# ===================================================
# Ë®≠ÂÆöÔºàbuild_rag„Å®Âêå„ÅòÂÄ§„Å´„Åô„ÇãÔºâ
# ===================================================
CHROMA_DB_PATH  = "./chroma_db"
COLLECTION_NAME = "manual_chunks"
EMBED_MODEL     = "paraphrase-multilingual-mpnet-base-v2"
TOP_K           = 5   # ‰∏ä‰Ωç‰Ωï‰ª∂ÂèñÂæó„Åô„Çã„Åã


# ===================================================
# Ê§úÁ¥¢Èñ¢Êï∞
# ===================================================
def search(query: str, collection, model, top_k: int = TOP_K):
    """
    „ÇØ„Ç®„É™ÊñáÂ≠óÂàó„Å´Ëøë„ÅÑ„ÉÅ„É£„É≥„ÇØ„ÇíChromaDB„Åã„ÇâÊ§úÁ¥¢„Åó„Å¶Ëøî„Åô
    """
    # „ÇØ„Ç®„É™„Çí„Éô„ÇØ„Éà„É´Âåñ
    query_vector = model.encode([query]).tolist()

    # ChromaDB„ÅßÈ°û‰ºº„ÉÅ„É£„É≥„ÇØ„ÇíÊ§úÁ¥¢
    results = collection.query(
        query_embeddings = query_vector,
        n_results        = top_k,
        include          = ["documents", "metadatas", "distances"]
    )

    return results


def show_results(query: str, results: dict):
    """
    Ê§úÁ¥¢ÁµêÊûú„ÇíË¶ã„ÇÑ„Åô„ÅèË°®Á§∫„Åô„Çã
    """
    print(f"\n{'='*60}")
    print(f"üîç Ê§úÁ¥¢„ÇØ„Ç®„É™: {query}")
    print(f"{'='*60}")

    docs      = results["documents"][0]
    metadatas = results["metadatas"][0]
    distances = results["distances"][0]

    for i, (doc, meta, dist) in enumerate(zip(docs, metadatas, distances)):
        similarity = 1 - dist   # „Ç≥„Çµ„Ç§„É≥Ë∑ùÈõ¢‚ÜíÈ°û‰ººÂ∫¶„Å´Â§âÊèõ
        print(f"\n--- ÁµêÊûú {i+1} (È°û‰ººÂ∫¶: {similarity:.3f}, „Éö„Éº„Ç∏: {meta['page_num']}) ---")
        print(doc[:300] + "..." if len(doc) > 300 else doc)

    print(f"\n{'='*60}")


# ===================================================
# „É°„Ç§„É≥Âá¶ÁêÜ
# ===================================================
if __name__ == "__main__":
    print("ChromaDBË™≠„ÅøËæº„Åø‰∏≠...")
    client     = chromadb.PersistentClient(path=CHROMA_DB_PATH)
    collection = client.get_collection(COLLECTION_NAME)
    model      = SentenceTransformer(EMBED_MODEL)

    print(f"‚úÖ Ë™≠„ÅøËæº„ÅøÂÆå‰∫ÜÔºàÁ∑è„ÉÅ„É£„É≥„ÇØÊï∞: {collection.count()} ‰ª∂Ôºâ")
    print("\nÊ§úÁ¥¢„ÇØ„Ç®„É™„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÁµÇ‰∫Ü„Åô„Çã„Å´„ÅØ 'q' „ÇíÂÖ•Âäõ„ÄÇ\n")

    # ===================================================
    # „ÉÜ„Çπ„ÉàÁî®„ÇØ„Ç®„É™ÔºàË≥™ÂïèÁ•®„Åã„ÇâÊäúÁ≤ã„Åó„Åü5ÂïèÔºâ
    # ===================================================
    test_queries = [
        "Êú¨ÈÉ®Âì° ‰ªªÂëΩ ÁÅΩÂÆ≥ÂØæÁ≠ñÊú¨ÈÉ® ÊßãÊàê",              # Q1
        "Êú¨ÈÉ® Ë®≠ÁΩÆ Âü∫Ê∫ñ È¢®Ê∞¥ÂÆ≥ Âú∞Èúá Ë≠¶Êàí„É¨„Éô„É´",       # Q2
        "ÂÆâÂê¶Á¢∫Ë™ç ÂÆüÊñΩ Âü∫Ê∫ñ ÂØæË±°ËÄÖ „Çø„Ç§„Éü„É≥„Ç∞",         # Q6
        "ÈÅøÈõ£ÊâÄ ÈñãË®≠ Âü∫Ê∫ñ È¢®Ê∞¥ÂÆ≥ Âú∞Èúá",                # Q71
        "ÈõªÂäõ „Ç¨„Çπ ÈÄö‰ø° Áü≥Ê≤π ÊÉÖÂ†±ÂèéÈõÜ „É©„Ç§„Éï„É©„Ç§„É≥",    # Q102
    ]

    for query in test_queries:
        results = search(query, collection, model)
        show_results(query, results)

    # ===================================================
    # ÂØæË©±„É¢„Éº„ÉâÔºàËá™ÂàÜ„Åß„ÇØ„Ç®„É™„ÇíÊâì„Å°Ëæº„Çì„ÅßË©¶„Åõ„ÇãÔºâ
    # ===================================================
    print("\n\nüí¨ ÂØæË©±„É¢„Éº„ÉâÈñãÂßãÔºàËá™Áî±„Å´Ê§úÁ¥¢„Åß„Åç„Åæ„ÅôÔºâ")
    while True:
        query = input("\nÊ§úÁ¥¢„ÇØ„Ç®„É™„ÇíÂÖ•Âäõ > ").strip()
        if query.lower() == "q":
            print("ÁµÇ‰∫Ü„Åó„Åæ„Åô„ÄÇ")
            break
        if not query:
            continue
        results = search(query, collection, model)
        show_results(query, results)